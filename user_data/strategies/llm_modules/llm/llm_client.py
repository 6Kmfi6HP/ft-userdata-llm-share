"""
LLMå®¢æˆ·ç«¯æ¨¡å—
è´Ÿè´£ä¸LLM APIäº¤äº’ï¼Œæ”¯æŒå‡½æ•°è°ƒç”¨
"""
import logging
from typing import Dict, Any, List, Optional
import requests
import json
from datetime import datetime

logger = logging.getLogger(__name__)


class LLMClient:
    """LLM APIå®¢æˆ·ç«¯"""

    def __init__(self, llm_config: Dict[str, Any], function_executor):
        """
        åˆå§‹åŒ–LLMå®¢æˆ·ç«¯

        Args:
            llm_config: LLMé…ç½®
            function_executor: å‡½æ•°æ‰§è¡Œå™¨
        """
        self.api_base = llm_config.get("api_base", "http://host.docker.internal:3120")
        self.api_key = llm_config.get("api_key", "")
        self.model = llm_config.get("model", "qwen/qwen3-coder-30b")
        # 2025-01-23 ä¼˜åŒ–ï¼šä»é…ç½®è¯»å–temperatureï¼ˆGoogleç™½çš®ä¹¦å»ºè®®æ¨ç†ä»»åŠ¡ç”¨0.0ï¼‰
        self.temperature = llm_config.get("temperature", 0.0)
        self.max_tokens = llm_config.get("max_tokens", 2500)
        self.timeout = llm_config.get("timeout", 60)

        self.function_executor = function_executor

        # å¯¹è¯å†å²(ç”¨äºä¸Šä¸‹æ–‡ç®¡ç†)
        self.conversation_history: List[Dict[str, Any]] = []
        self.max_history_length = 5  # ä¿ç•™æœ€è¿‘Nè½®å¯¹è¯

        logger.info(f"LLMå®¢æˆ·ç«¯å·²åˆå§‹åŒ–: {self.model}")

    def call_with_functions(
        self,
        messages: List[Dict[str, str]],
        functions: Optional[List[Dict[str, Any]]] = None,
        max_iterations: int = 5
    ) -> Dict[str, Any]:
        """
        è°ƒç”¨LLMå¹¶æ”¯æŒå‡½æ•°è°ƒç”¨

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            functions: å¯ç”¨çš„å‡½æ•°åˆ—è¡¨
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°(é˜²æ­¢æ— é™å¾ªç¯)

        Returns:
            LLMå“åº”å’Œæ‰§è¡Œç»“æœ
        """
        if functions is None:
            functions = self.function_executor.get_all_tools_schema()

        iteration = 0
        current_messages = messages.copy()
        function_call_history = []

        while iteration < max_iterations:
            iteration += 1

            logger.debug(f"ğŸ”„ è¿­ä»£ {iteration}/{max_iterations} å¼€å§‹")

            try:
                # è°ƒç”¨LLM API
                response = self._call_api(current_messages, functions)

                if not response:
                    return {
                        "success": False,
                        "error": "APIè°ƒç”¨å¤±è´¥",
                        "iteration": iteration
                    }

                # è§£æå“åº”
                choice = response.get("choices", [{}])[0]
                message = choice.get("message", {})
                finish_reason = choice.get("finish_reason", "")

                # æå–æ¶ˆæ¯å†…å®¹ï¼ˆå…¼å®¹æ¨ç†æ¨¡å‹çš„ç‰¹æ®Šæ ¼å¼ï¼‰
                message_content = self._extract_message_content(message)

                # æ£€æŸ¥æ˜¯å¦æœ‰å‡½æ•°è°ƒç”¨
                tool_calls = message.get("tool_calls", [])

                if not tool_calls or finish_reason == "stop":
                    # æ£€æŸ¥æ˜¯å¦çœŸçš„æ²¡æœ‰å‡½æ•°è°ƒç”¨
                    if not function_call_history:
                        # LLM å®Œå…¨æ²¡æœ‰è°ƒç”¨ä»»ä½•å‡½æ•°
                        logger.warning(f"âš ï¸  LLM æœªè°ƒç”¨ä»»ä½•å‡½æ•° (è¿­ä»£ {iteration}/{max_iterations}, finish_reason: {finish_reason})")
                        logger.warning(f"æ¶ˆæ¯å†…å®¹: {message_content[:200] if message_content else '(ç©º)'}")
                        
                        # å¦‚æœè¿˜æœ‰è¿­ä»£æœºä¼šï¼Œæ·»åŠ å¼ºåˆ¶æç¤ºå¹¶é‡è¯•
                        if iteration < max_iterations:
                            logger.info(f"ğŸ”„ å°è¯•å‘é€å¼ºåˆ¶å‡½æ•°è°ƒç”¨æç¤º (å‰©ä½™ {max_iterations - iteration} æ¬¡æœºä¼š)")
                            
                            # æ·»åŠ å¼ºåˆ¶æ€§æç¤ºæ¶ˆæ¯
                            force_message = {
                                "role": "user",
                                "content": (
                                    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                                    "ğŸš¨ CRITICAL ERROR DETECTED ğŸš¨\n"
                                    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
                                    "âš ï¸  SYSTEM REQUIREMENT VIOLATION:\n"
                                    "You FAILED to call a function in your last response.\n\n"
                                    "âŒ What you did: Outputted text only\n"
                                    "âœ… What you MUST do: Call exactly ONE function\n\n"
                                    "ğŸ”§ MANDATORY ACTIONS (choose one):\n"
                                    "  1. signal_entry_long(pair, leverage, reason) - Open long\n"
                                    "  2. signal_entry_short(pair, leverage, reason) - Open short\n"
                                    "  3. signal_wait(reason) - Wait/observe\n"
                                    "  4. signal_hold(reason) - Keep current position\n"
                                    "  5. signal_exit(pair, trade_score, reason) - Close position\n"
                                    "  6. adjust_position(pair, position_change_pct, reason) - Adjust\n\n"
                                    "ğŸ’¡ IMPORTANT CLARIFICATIONS:\n"
                                    "  â€¢ Functions are ACTIONS, not suggestions\n"
                                    "  â€¢ \"Waiting\" requires calling signal_wait()\n"
                                    "  â€¢ Explanations go in the 'reason' parameter\n"
                                    "  â€¢ The system expects tool_calls, not conversational text\n\n"
                                    "ğŸ“Œ RESPOND NOW: Call the appropriate function immediately.\n"
                                    "    No more text-only responses will be accepted.\n"
                                    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
                                )
                            }
                            
                            # æ·»åŠ  LLM çš„å“åº”ï¼ˆå¦‚æœæœ‰ï¼‰åˆ°å†å²
                            if message_content:
                                current_messages.append({
                                    "role": "assistant",
                                    "content": message_content
                                })
                            
                            # æ·»åŠ å¼ºåˆ¶æç¤º
                            current_messages.append(force_message)
                            
                            # ç»§ç»­ä¸‹ä¸€è½®è¿­ä»£
                            logger.info(f"ç»§ç»­ä¸‹ä¸€è½®è¿­ä»£...")
                            continue
                        else:
                            # å·²è¾¾æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œä»æœªè°ƒç”¨å‡½æ•°
                            logger.error(f"âŒ å·²è¾¾æœ€å¤§è¿­ä»£æ¬¡æ•° ({max_iterations})ï¼ŒLLM å§‹ç»ˆæœªè°ƒç”¨ä»»ä½•å‡½æ•°!")
                            logger.error("è¿™é€šå¸¸è¡¨ç¤º:")
                            logger.error("  1. tool_choice è®¾ç½®ä¸æ­£ç¡® (åº”ä¸º 'required')")
                            logger.error("  2. æ¨¡å‹ä¸æ”¯æŒ function calling")
                            logger.error("  3. API è¿”å›æ ¼å¼å¼‚å¸¸")
                            logger.error("  4. prompt æŒ‡ç¤ºä¸å¤Ÿæ˜ç¡®")
                            
                            return {
                                "success": False,
                                "error": f"LLM åœ¨ {max_iterations} æ¬¡è¿­ä»£åä»æœªè°ƒç”¨ä»»ä½•äº¤æ˜“å‡½æ•°",
                                "message": message_content,
                                "function_calls": [],
                                "iterations": iteration,
                                "finish_reason": finish_reason
                            }
                    else:
                        # å·²ç»è°ƒç”¨è¿‡å‡½æ•°,ç°åœ¨æ­£å¸¸ç»“æŸ
                        logger.debug(f"âœ… å†³ç­–å®Œæˆ (è¿­ä»£{iteration}, åŸå› : {finish_reason or 'å‡½æ•°è°ƒç”¨å®Œæˆ'})")
                        return {
                            "success": True,
                            "message": message_content,
                            "function_calls": function_call_history,
                            "iterations": iteration,
                            "finish_reason": finish_reason
                        }

                # æ‰§è¡Œå‡½æ•°è°ƒç”¨
                logger.debug(f"ğŸ“ æœ¬æ¬¡è¿­ä»£éœ€è¦è°ƒç”¨ {len(tool_calls)} ä¸ªå‡½æ•°")
                function_results = []
                should_terminate = False  # æ˜¯å¦é‡åˆ°ç»ˆæ­¢æ€§å‡½æ•°

                for tool_call in tool_calls:
                    func_name = tool_call.get("function", {}).get("name", "")
                    func_args_str = tool_call.get("function", {}).get("arguments", "{}")

                    try:
                        func_args = json.loads(func_args_str) if isinstance(func_args_str, str) else func_args_str
                    except json.JSONDecodeError as e:
                        logger.error(f"è§£æå‡½æ•°å‚æ•°å¤±è´¥: {e}")
                        func_args = {}

                    # æ‰§è¡Œå‡½æ•°
                    result = self.function_executor.execute_function(func_name, func_args)

                    # æ£€æŸ¥æ˜¯å¦ä¸ºç»ˆæ­¢æ€§å‡½æ•°
                    if result.get("_is_terminal", False):
                        should_terminate = True
                        logger.info(f"ğŸ›‘ æ£€æµ‹åˆ°ç»ˆæ­¢æ€§å‡½æ•° '{func_name}'ï¼Œå†³ç­–æµç¨‹å°†ç»“æŸ")

                    # è®°å½•
                    function_call_history.append({
                        "function": func_name,
                        "arguments": func_args,
                        "result": result
                    })

                    function_results.append({
                        "role": "tool",
                        "tool_call_id": tool_call.get("id", ""),
                        "name": func_name,
                        "content": json.dumps(result, ensure_ascii=False)
                    })

                # å¦‚æœé‡åˆ°ç»ˆæ­¢æ€§å‡½æ•°ï¼Œç«‹å³è¿”å›
                if should_terminate:
                    logger.info(f"âœ… å†³ç­–å®Œæˆ (è¿­ä»£{iteration}, è°ƒç”¨ç»ˆæ­¢æ€§å‡½æ•°)")
                    return {
                        "success": True,
                        "message": message_content,
                        "function_calls": function_call_history,
                        "iterations": iteration,
                        "finish_reason": "terminal_function"
                    }

                # å°†å‡½æ•°è°ƒç”¨ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯å†å²
                current_messages.append(message)
                current_messages.extend(function_results)

            except Exception as e:
                logger.error(f"LLMè°ƒç”¨å¤±è´¥ (è¿­ä»£{iteration}): {e}")
                return {
                    "success": False,
                    "error": str(e),
                    "iteration": iteration,
                    "function_calls": function_call_history
                }

        # è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆæå°‘å‘ç”Ÿï¼‰
        logger.debug(f"è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°: {max_iterations}")
        return {
            "success": False,
            "error": "è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°",
            "iterations": max_iterations,
            "function_calls": function_call_history
        }

    def _call_api(
        self,
        messages: List[Dict[str, str]],
        functions: List[Dict[str, Any]]
    ) -> Optional[Dict[str, Any]]:
        """
        è°ƒç”¨LLM API

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            functions: å‡½æ•°åˆ—è¡¨

        Returns:
            APIå“åº”
        """
        try:
            url = f"{self.api_base}/v1/chat/completions"
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.api_key}"
            }

            # æ„å»ºpayload
            payload = {
                "model": self.model,
                "messages": messages,
                "tools": [{"type": "function", "function": f} for f in functions]
            }
            # Gemini æ¨¡å‹ç‰¹æ®Šé…ç½®: å¯ç”¨æ€è€ƒæ¨¡å¼
            if self.model.startswith("gemini-"):
                payload["extra_body"] = {"google": {"thinking_config": {"thinking_budget": 24576, "include_thoughts": True}}}
            # å¼ºåˆ¶è¦æ±‚è°ƒç”¨å‡½æ•° (æ¨¡å‹å…¼å®¹æ€§æ£€æŸ¥)
            # OpenAI: ä½¿ç”¨ "required" (æ ‡å‡†æ¨¡å¼)
            payload["tool_choice"] = "required"
            
            # åªæ·»åŠ é None çš„å¯é€‰å‚æ•°
            if self.temperature is not None:
                payload["temperature"] = self.temperature
            if self.max_tokens is not None:
                payload["max_tokens"] = self.max_tokens

            # è®°å½•å®Œæ•´çš„promptä¿¡æ¯ï¼ˆæ§åˆ¶å°è¾“å‡ºï¼‰
            logger.info("=" * 80)
            logger.info("ğŸ“¤ å‘é€ç»™LLMçš„å®Œæ•´ä¿¡æ¯")
            logger.info("=" * 80)
            logger.info(f"æ¨¡å‹: {self.model}")
            logger.info(f"æ¶ˆæ¯æ•°é‡: {len(messages)}")
            logger.info(f"å¯ç”¨å‡½æ•°æ•°é‡: {len(functions)}")
            logger.info("-" * 80)

            # æ‰“å°æ¯æ¡æ¶ˆæ¯ï¼ˆå®Œæ•´ä¸æˆªå–ï¼‰
            for idx, msg in enumerate(messages, 1):
                role = msg.get("role", "unknown")
                content = msg.get("content", "")
                logger.info(f"æ¶ˆæ¯ #{idx} [è§’è‰²: {role}]")
                if content:
                    logger.info(f"å®Œæ•´å†…å®¹:\n{content}")

                # å¦‚æœæœ‰tool_callsï¼Œä¹Ÿæ‰“å°å‡ºæ¥
                if "tool_calls" in msg:
                    logger.info(f"Tool Calls: {json.dumps(msg['tool_calls'], ensure_ascii=False, indent=2)}")

                logger.info("-" * 80)

            # æ‰“å°å¯ç”¨çš„å‡½æ•°åˆ—è¡¨ï¼ˆå®Œæ•´ï¼‰
            logger.info("å¯ç”¨å‡½æ•°åˆ—è¡¨:")
            for func in functions:
                logger.info(f"  - {func.get('name', 'unknown')}: {func.get('description', 'no description')}")
            logger.info("=" * 80)

            logger.debug(f"è°ƒç”¨LLM API: {self.model}")

            response = requests.post(
                url,
                json=payload,
                headers=headers,
                timeout=self.timeout
            )

            if response.status_code != 200:
                logger.error(f"APIè¿”å›é”™è¯¯: {response.status_code} - {response.text}")
                return None

            response_json = response.json()

            # è®°å½•LLMçš„å“åº”ï¼ˆå®Œæ•´ä¸æˆªå–ï¼‰
            logger.info("=" * 80)
            logger.info("ğŸ“¥ LLMè¿”å›çš„å®Œæ•´å“åº”")
            logger.info("=" * 80)
            choice = response_json.get("choices", [{}])[0]
            message = choice.get("message", {})
            finish_reason = choice.get("finish_reason", "")

            logger.info(f"å®ŒæˆåŸå› : {finish_reason}")

            # æå–å¹¶æ‰“å°å†…å®¹ï¼ˆå®Œæ•´ï¼‰
            content = message.get("content", "")
            if content:
                logger.info(f"å“åº”å†…å®¹ï¼ˆå®Œæ•´ï¼‰:\n{content}")

            # æ‰“å°æ€è€ƒè¿‡ç¨‹ï¼ˆå®Œæ•´ï¼‰
            think = message.get("think", "")
            reasoning = message.get("reasoning", "")
            if think:
                logger.info(f"æ€è€ƒè¿‡ç¨‹ï¼ˆå®Œæ•´ï¼‰:\n{think}")
            if reasoning:
                logger.info(f"æ¨ç†è¿‡ç¨‹ï¼ˆå®Œæ•´ï¼‰:\n{reasoning}")

            # æ‰“å°tool_callsï¼ˆå®Œæ•´ï¼‰
            tool_calls = message.get("tool_calls", [])
            if tool_calls:
                logger.info(f"å‡½æ•°è°ƒç”¨æ•°é‡: {len(tool_calls)}")
                for tc in tool_calls:
                    func_name = tc.get("function", {}).get("name", "unknown")
                    func_args = tc.get("function", {}).get("arguments", "{}")
                    logger.info(f"  è°ƒç”¨å‡½æ•°: {func_name}")
                    logger.info(f"  å®Œæ•´å‚æ•°: {func_args}")

            logger.info("=" * 80)

            return response_json

        except requests.Timeout:
            logger.error("APIè¯·æ±‚è¶…æ—¶")
            return None
        except Exception as e:
            logger.error(f"APIè°ƒç”¨å¼‚å¸¸: {e}")
            return None

    def _extract_message_content(self, message: Dict[str, Any]) -> str:
        """
        æå–æ¶ˆæ¯å†…å®¹ï¼Œå…¼å®¹æ¨ç†æ¨¡å‹çš„ç‰¹æ®Šå“åº”æ ¼å¼

        Args:
            message: APIè¿”å›çš„messageå¯¹è±¡

        Returns:
            æå–çš„æ¶ˆæ¯å†…å®¹
        """
        # æ£€æŸ¥å¹¶è®°å½•æ€è€ƒè¿‡ç¨‹ï¼ˆå¦‚æœæœ‰ï¼‰
        think = message.get("think", "")
        reasoning = message.get("reasoning", "")
        reasoning_content = message.get("reasoning_content", "")

        if think:
            logger.info(f"[æ¨¡å‹æ€è€ƒè¿‡ç¨‹]\n{think}")
        elif reasoning:
            logger.info(f"[æ¨¡å‹æ¨ç†è¿‡ç¨‹]\n{reasoning}")
        elif reasoning_content:
            logger.info(f"[æ¨¡å‹æ¨ç†å†…å®¹]\n{reasoning_content}")

        # ä¼˜å…ˆä½¿ç”¨ content å­—æ®µï¼ˆæ ‡å‡†æ ¼å¼ - æœ€ç»ˆå†³ç­–ï¼‰
        content = message.get("content", "")
        if content:
            return content

        # å¦‚æœæ²¡æœ‰ contentï¼Œå°è¯•ä½¿ç”¨ reasoning ç›¸å…³å­—æ®µ
        # æŸäº›æ¨ç†æ¨¡å‹å¯èƒ½åªè¿”å› reasoning è€Œä¸è¿”å› content
        if reasoning:
            logger.info("æœªæ‰¾åˆ° content å­—æ®µï¼Œä½¿ç”¨ reasoning ä½œä¸ºå“åº”")
            return reasoning

        if think:
            logger.info("æœªæ‰¾åˆ° content å­—æ®µï¼Œä½¿ç”¨ think ä½œä¸ºå“åº”")
            return think

        if reasoning_content:
            logger.info("æœªæ‰¾åˆ° content å­—æ®µï¼Œä½¿ç”¨ reasoning_content ä½œä¸ºå“åº”")
            return reasoning_content

        # å¦‚æœæœ‰tool_callsï¼Œè¯´æ˜LLMç›´æ¥è°ƒç”¨å‡½æ•°è€Œæ²¡æœ‰è¾“å‡ºæ–‡æœ¬ï¼Œè¿™æ˜¯æ­£å¸¸çš„
        if message.get("tool_calls"):
            logger.debug("æ¶ˆæ¯ä¸­åªæœ‰tool_callsï¼Œæ— æ–‡æœ¬å†…å®¹ï¼ˆæ­£å¸¸ï¼‰")
            return ""

        # å¦‚æœæ—¢æ²¡æœ‰å†…å®¹ä¹Ÿæ²¡æœ‰tool_callsï¼Œæ‰æ˜¯å¼‚å¸¸æƒ…å†µ
        logger.error("âŒ æ¶ˆæ¯ä¸­æœªæ‰¾åˆ° contentã€thinkã€reasoningã€reasoning_content æˆ– tool_calls å­—æ®µ")
        logger.error(f"å®Œæ•´ message å¯¹è±¡: {json.dumps(message, ensure_ascii=False)}")
        return ""

    def simple_call(
        self,
        messages: List[Dict[str, str]],
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        timeout: Optional[float] = None
    ) -> Optional[str]:
        """
        ç®€å•è°ƒç”¨(ä¸ä½¿ç”¨å‡½æ•°è°ƒç”¨)

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            temperature: å¯é€‰ï¼Œè¦†ç›–å®ä¾‹é»˜è®¤æ¸©åº¦å€¼
            max_tokens: å¯é€‰ï¼Œè¦†ç›–å®ä¾‹é»˜è®¤æœ€å¤§tokenæ•°
            timeout: å¯é€‰ï¼Œè¦†ç›–å®ä¾‹é»˜è®¤è¶…æ—¶æ—¶é—´

        Returns:
            LLMå“åº”æ–‡æœ¬
        """
        try:
            url = f"{self.api_base}/v1/chat/completions"
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.api_key}"
            }

            payload = {
                "model": self.model,
                "messages": messages
            }

            # ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨å®ä¾‹é»˜è®¤å€¼
            temp_value = temperature if temperature is not None else self.temperature
            max_tokens_value = max_tokens if max_tokens is not None else self.max_tokens
            timeout_value = timeout if timeout is not None else self.timeout

            # åªæ·»åŠ é None çš„å¯é€‰å‚æ•°
            if temp_value is not None:
                payload["temperature"] = temp_value
            if max_tokens_value is not None:
                payload["max_tokens"] = max_tokens_value

            response = requests.post(
                url,
                json=payload,
                headers=headers,
                timeout=timeout_value
            )

            if response.status_code != 200:
                logger.error(f"APIè¿”å›é”™è¯¯: {response.status_code}")
                return None

            data = response.json()
            content = data.get("choices", [{}])[0].get("message", {}).get("content", "")

            return content

        except Exception as e:
            logger.error(f"ç®€å•è°ƒç”¨å¤±è´¥: {e}")
            return None

    def manage_context_window(
        self,
        messages: List[Dict[str, str]],
        max_tokens: int = 6000
    ) -> List[Dict[str, str]]:
        """
        ç®¡ç†ä¸Šä¸‹æ–‡çª—å£ï¼Œé¿å…è¶…å‡ºtokené™åˆ¶

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            max_tokens: æœ€å¤§tokenæ•°

        Returns:
            ç²¾ç®€åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        # ç®€å•ä¼°ç®—: 1 token â‰ˆ 2.5 å­—ç¬¦
        estimated_tokens = sum(len(m.get("content", "")) for m in messages) / 2.5

        if estimated_tokens <= max_tokens:
            return messages

        # ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯å’Œæœ€è¿‘çš„ç”¨æˆ·æ¶ˆæ¯
        system_messages = [m for m in messages if m.get("role") == "system"]
        other_messages = [m for m in messages if m.get("role") != "system"]

        # ä»åå¾€å‰ä¿ç•™æ¶ˆæ¯ï¼Œç›´åˆ°æ¥è¿‘tokené™åˆ¶
        kept_messages = []
        current_tokens = sum(len(m.get("content", "")) for m in system_messages) / 2.5

        for msg in reversed(other_messages):
            msg_tokens = len(msg.get("content", "")) / 2.5
            if current_tokens + msg_tokens > max_tokens * 0.9:  # ä¿ç•™10%ä½™é‡
                break
            kept_messages.insert(0, msg)
            current_tokens += msg_tokens

        return system_messages + kept_messages

    def add_to_history(self, role: str, content: str):
        """æ·»åŠ æ¶ˆæ¯åˆ°å†å²"""
        self.conversation_history.append({
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat()
        })

        # é™åˆ¶å†å²é•¿åº¦
        if len(self.conversation_history) > self.max_history_length * 2:
            self.conversation_history = self.conversation_history[-self.max_history_length * 2:]

    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.conversation_history.clear()
        logger.info("å¯¹è¯å†å²å·²æ¸…ç©º")

    def get_history(self, include_timestamp: bool = False) -> List[Dict[str, Any]]:
        """è·å–å¯¹è¯å†å²"""
        if include_timestamp:
            return self.conversation_history.copy()

        return [
            {"role": m["role"], "content": m["content"]}
            for m in self.conversation_history
        ]

    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "model": self.model,
            "api_base": self.api_base,
            "conversation_length": len(self.conversation_history),
            "max_history_length": self.max_history_length
        }
